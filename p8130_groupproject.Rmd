---
title: "p8130_GroupProject"
author: "jiaying Ning"
date: "12/12/2020"
output: html_document
---


```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)
library(leaps)
library(corrplot) 
library(MASS)

knitr::opts_chunk$set(
  fig.width = 6,
    fig.asp = .6,
  out.width = "90%"

)

theme_set(theme_minimal()+theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_color_discrete = scale_color_viridis_d
scale_fill_discrete =scale_fill_viridis_d
```

### Import data
```{r load the data}
HateCrime_df=
   read_csv("./data/HateCrimes.csv") 
#Noting we do not have hatecrime stats for Hawaii,North Dakota,South Dakota,and Wyoming
```






### Data exploration: descriptive statistics and visualization.

#### Explore the distribution of the outcome and consider potential transformations (if the case).

For analysis purpose, I delelte rows that do not have hate-crime record, and convert hate crime data to numerical value
```{r}
HateCrime_df =
  HateCrime_df %>% 
  filter(hate_crimes_per_100k_splc != "N/A") %>%
    na.omit() %>%
  mutate(hate_crimes_per_100k_splc = as.numeric(hate_crimes_per_100k_splc))
```



##### Explore the distribution of the outcome

```{r}
library(plotly)

#HateCrime_df %>% 
#  filter(hate_crimes_per_100k_splc != "N/A") %>%
 # mutate(hate_crimes_per_100k_splc = as.numeric(hate_crimes_per_100k_splc)) %>% 
 # ggplot(aes(x=hate_crimes_per_100k_splc))+
 # geom_boxplot()+
 # coord_flip()


HateCrime_df %>% 
  mutate(text_label = str_c(" hate crime rate per 100,000 population: ", hate_crimes_per_100k_splc, "\nState: ", state)) %>% 
  plot_ly(y = ~hate_crimes_per_100k_splc, type = "box", colors = "viridis",text = ~text_label)
```
```{r}

   
HateCrime_df %>% 
  mutate(state = fct_reorder(state, hate_crimes_per_100k_splc)) %>% 
  ggplot(aes(x=hate_crimes_per_100k_splc)) +
  geom_histogram(fill="darkorange2") +
  labs(x = "hate crime rate per 100,000 population", y = "frequency")
   
# plot_ly(y = ~price, color = ~neighbourhood, type = "box", colors = "viridis")
```


```{r}
HateCrime_df %>% 
  mutate(state = fct_reorder(state, hate_crimes_per_100k_splc)) %>% 
  ggplot(aes(x=state,y=hate_crimes_per_100k_splc,fill=state)) +
  geom_bar( stat = "identity")+
   theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
  labs(x = "state", y = "hate crime rate per 100,000 population")+
  theme(legend.position = "none")
```

```{r}
summary(HateCrime_df$hate_crimes_per_100k_splc)
```

- From the boxplot and histogram we see that the distribution of hate crime rate data is skewed to the right, with a couple outliers containing much higher hate crime rate than the rest of data.
- According to the summary and boxplot, we see most our hate crime rate data are between 0.14271(q1) and 0.35693(q3) interval with mean of 0.30409 and median of 0.22620. The reason why we have higher mean than median is also because mean is influence by the outliers that have extraordinary high hate crime. 
- Specifically, from the boxplot and bar graph we see two outliers are identified:
  + record from District of Columbia with hate crime rate of 1.522
  + record from Oregon with hate crime rate of 0.8328

##### consider potential transformations (if the case).

###### Log Transformation
```{r}
log=
HateCrime_df %>% 
  mutate(state = fct_reorder(state, hate_crimes_per_100k_splc),
       hate_crimes_per_100k_splc = log(hate_crimes_per_100k_splc)  ) %>% 
  ggplot(aes(x=hate_crimes_per_100k_splc)) +
  geom_histogram(fill="firebrick4") +
  labs(title= "log transformation",x = "log(hate crime rate per 100,000 population)", y = "frequency")
```

###### square root Transformation
```{r}
squre_root=
HateCrime_df %>% 
  mutate(state = fct_reorder(state, hate_crimes_per_100k_splc),
       hate_crimes_per_100k_splc = (hate_crimes_per_100k_splc)^(0.5)  ) %>% 
  ggplot(aes(x=hate_crimes_per_100k_splc)) +
  geom_histogram(fill="firebrick4") +
  labs(title= "square root transformation",x = "sqrt(hate crime rate per 100,000 population)", y = "frequency")
```

###### cube root Transformation

```{r}
cube_root=
HateCrime_df %>% 
  mutate(state = fct_reorder(state, hate_crimes_per_100k_splc),
       hate_crimes_per_100k_splc = (hate_crimes_per_100k_splc)^(1/3)  ) %>% 
  ggplot(aes(x=hate_crimes_per_100k_splc)) +
  geom_histogram(fill="firebrick4") +
  labs(title= "cube root transformation",x = "cube_root(hate crime rate per 100,000 population)", y = "frequency")
```

```{r}
(log+squre_root)/cube_root
```
 
- **comment**:Just by looking at the histogram distribution, seems like **log transformation** is the best transformation to convert the current skewed distribution into a relatively normal one. We might need to perform boxcox and checking the diagnostic plot to be sure. 


### Model Building.

- The initial analysis published by FiveThirtyEight showed that income inequality was the main predictor of hate crimes rates. 
  + Verify if this association holds true in this dataset, but also explore associations of all the other covariates mentioned above and draw your own conclusions.
  + In your multiple regression model, be careful of variables that are highly correlated and be selective of the ones that you choose to include in the analysis.
  + Consider interactions between variables (e.g., urbanization), and if the case, fit stratified models.

#### visualizing Correlation
```{r}
HateCrime_df%>%
  select(-state,-unemployment,-urbanization) %>%
pairs()

```

```{r}

HateCrime_df%>%
  select(-state,-unemployment,-urbanization) %>%
cor()
```

- **comment**: 
  + Looking at the correlation matrix, specifically on the correlation between hate crime rate and the rest of covariates we see that gini_index, which measures income inequality, does have the strongest correlation with hate crime rate, similarly, median household income have relatively high correlation with hate crime rate as well, indicating the difference in income does have strong influence on hate crime rate.
  + Note about potential collinearity: From the correlation matrix we see that `percent noncitizen population` and `percent nonwhite population` have have correlation of -.7526. Similarly, another high correlation of 0.65 is observed between `median household income` and `percent of adults 25 and older with at least a high school degree` 
  + All these observation are made without removing any potential outlier and influential point
  
  

#### Fit model

##### Fit model with every term
```{r}


mult_fit <- lm(hate_crimes_per_100k_splc ~ median_household_income + perc_non_white + perc_non_citizen + perc_population_with_high_school_degree + gini_index + unemployment + urbanization, data=HateCrime_df)
summary(mult_fit)
```

##### Performing Box-Cox Transformation

```{r}
boxcox(mult_fit)
```
- From Boxcox we also see the lambda value is close to 0 which means a log-transformation is suggested in this case.

##### Comparing diagnosed plot before and after performing box-cox

```{r}
par(mfrow=c(2,2))
plot(mult_fit)
```

###### Performing log transformation
```{r}
mult_fit_log <- lm(log(hate_crimes_per_100k_splc) ~ median_household_income + perc_non_white + perc_non_citizen + perc_population_with_high_school_degree + gini_index + unemployment + urbanization, data=HateCrime_df)
summary(mult_fit_log)
```

```{r}
par(mfrow=c(2,2))
plot(mult_fit_log)
```

- **comment** By comparing the diagnostic plot we see that after applying log transformation, we were able to reduce curvature line in the `residual versus fitted plot` and `sqrt(standardized residual) versus fitted value plot`, the horizontal band is also closer to zero in the `residuals vs fitted value plot`, which means log transformation does enable us to have more equally spread error variance. Log transformation also reduce the presence of heavy tails in `QQplot` in which indicates residuals seem to follow normal distribution in the current model.Finally, log transformation reduce the effect of influence point as indicate in the `Residuals vs Leverage` plot. Before transformation, one point is outside of the dashed line 1, which means we have an influential point that have cook's distance larger than 1. After log transformation, all observation are within the dashed line meaning no influential point is shown in the current model. 

```{r}
step(mult_fit_log, direction='backward')

```

```{r}
stepwised_multi_fit = lm( log(hate_crimes_per_100k_splc) ~ perc_population_with_high_school_degree + 
    gini_index, data = HateCrime_df)

summary(stepwised_multi_fit)
```

